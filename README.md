# AMQA: Adversarial Medical Question Answering Dataset

This repository contains the code, data, and evaluation tools for **AMQA** (Adversarial Medical Question Answering), a dataset and benchmarking framework for evaluating demographic bias in large language models (LLMs) within medical QA scenarios.

---

## ğŸ“˜ Overview

AMQA is designed to reveal latent biases in LLMs through systematically constructed counterfactual variants of USMLE-style clinical questions. It features:

- **801 neutralized clinical vignettes**
- **6 adversarial variants per vignette** targeting:
  - Race (Black vs. White)
  - Gender (Male vs. Female)
  - Socioeconomic status (High vs. Low Income)
- **Multi-agent adversarial generation pipeline**
- **Automated and human-reviewed evaluation**
- **Support for individual fairness (counterfactual fairness) and group fairness (accuracy gap)**

---

## ğŸ“ Repository Structure

```text
AMQA/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ AMQA_dataset.jsonl           # Final dataset with original, neutralized, and adversarial variants
â”‚   â”œâ”€â”€ examples/                    # Sample vignette examples and annotations
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ evaluate_accuracy_gap.py     # Scripts for accuracy and fairness evaluation
â”‚   â”œâ”€â”€ run_mcnemar_test.py          # McNemar significance testing between counterfactual pairs
â”œâ”€â”€ generation/
â”‚   â”œâ”€â”€ agents/                      # Multi-agent pipeline (Generation, Fusion, Evaluation)
â”‚   â”œâ”€â”€ prompts/                     # Prompt templates for LLM calls
â”œâ”€â”€ figures/
â”‚   â”œâ”€â”€ pipeline.png                 # Generation pipeline diagram
â”œâ”€â”€ README.md
